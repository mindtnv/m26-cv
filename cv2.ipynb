{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e78efe0d-a3c2-4d2d-9893-9459785c33ba",
   "metadata": {
    "id": "e78efe0d-a3c2-4d2d-9893-9459785c33ba"
   },
   "source": "Локальные дескрипторы и сверточные нейронные сети\n\n**Антонов Михаил Евгеньевич, М-26**\n___"
  },
  {
   "cell_type": "markdown",
   "id": "a15fff7b-5098-42dd-a80c-39576b458814",
   "metadata": {
    "id": "a15fff7b-5098-42dd-a80c-39576b458814"
   },
   "source": [
    "#### Оглавление\n",
    "1. Setup: подготовка окружения и импорты\n",
    "2. Данные: описание и загрузка изображений\n",
    "3. Локальные дескрипторы (SIFT) и backpropagation\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a85fb8-b7e4-4cd6-a5fb-a842e7fb68a9",
   "metadata": {
    "id": "09a85fb8-b7e4-4cd6-a5fb-a842e7fb68a9"
   },
   "source": [
    "## 1. Setup: подготовка окружения и импорты"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Установка зависимостей (раскомментировать при первом запуске)\n# !pip install opencv-python opencv-contrib-python -q\n# !pip install numpy matplotlib -q\n# !pip install datasets torchvision -q",
   "metadata": {
    "id": "77vAUq1pBJQn"
   },
   "id": "77vAUq1pBJQn",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import os\nimport urllib.request\nfrom typing import Tuple, List, Optional\n\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Subset\nfrom torchvision import transforms\nfrom torchvision.models import resnet18\nfrom datasets import load_dataset\n\n%matplotlib inline\n\n# Константы\nMAX_IMAGE_DIM = 800\nRANDOM_SEED = 42\n\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)",
   "metadata": {
    "id": "BkGh29E3BMUL"
   },
   "id": "BkGh29E3BMUL",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def resize_keep_aspect(img: np.ndarray, max_dim: int = MAX_IMAGE_DIM) -> np.ndarray:\n    \"\"\"Изменяет размер изображения с сохранением пропорций.\n    \n    Args:\n        img: Входное изображение\n        max_dim: Максимальный размер по большей стороне\n        \n    Returns:\n        Изображение с изменённым размером\n    \"\"\"\n    h, w = img.shape[:2]\n    scale = min(1.0, max_dim / max(h, w))\n    if scale < 1.0:\n        new_size = (int(w * scale), int(h * scale))\n        img = cv2.resize(img, new_size, interpolation=cv2.INTER_AREA)\n    return img\n\n\ndef load_and_prepare(path: str) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Загружает и подготавливает изображение.\n    \n    Args:\n        path: Путь к изображению\n        \n    Returns:\n        Кортеж (цветное изображение BGR, изображение в оттенках серого)\n        \n    Raises:\n        ValueError: Если изображение не удалось загрузить\n    \"\"\"\n    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n    if img is None:\n        raise ValueError(f\"Не удалось загрузить изображение: {path}\")\n\n    if img.dtype != np.uint8:\n        img = (np.clip(img, 0, 1) * 255).astype(np.uint8)\n\n    if img.ndim == 3 and img.shape[2] == 4:\n        img = cv2.cvtColor(img, cv2.COLOR_RGBA2BGR)\n\n    img = resize_keep_aspect(img)\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n    return img, gray\n\n\ndef download_images(urls: List[str], output_dir: str = \"data\") -> Tuple[List[np.ndarray], List[np.ndarray]]:\n    \"\"\"Загружает изображения по URL и подготавливает их.\n    \n    Args:\n        urls: Список URL изображений\n        output_dir: Директория для сохранения\n        \n    Returns:\n        Кортеж (список цветных изображений, список grayscale изображений)\n    \"\"\"\n    os.makedirs(output_dir, exist_ok=True)\n    \n    images = []\n    gray_images = []\n    \n    for i, url in enumerate(urls):\n        filename = os.path.join(output_dir, f\"image_{i}.jpg\")\n        try:\n            urllib.request.urlretrieve(f\"{url}?w=800&h=600&fit=crop\", filename)\n            img, gray = load_and_prepare(filename)\n            images.append(img)\n            gray_images.append(gray)\n            print(f\"Загружено: {filename} - размер: {img.shape}\")\n        except Exception as e:\n            print(f\"Ошибка загрузки {url}: {e}\")\n    \n    return images, gray_images\n\n\n# Загрузка изображений\nprint(\"Загрузка изображений...\")\n\nIMAGE_URLS = [\n    \"https://images.unsplash.com/photo-1574158622682-e40e69881006\",  # Кошка\n    \"https://images.unsplash.com/photo-1543466835-00a7907e9de1\",    # Собака\n]\n\nimages, gray_images = download_images(IMAGE_URLS)\ntitles = [f\"Изображение {i+1}\" for i in range(len(images))]\n\n# Визуализация\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\n\nfor i, (img, gray, title) in enumerate(zip(images, gray_images, titles)):\n    axes[0, i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    axes[0, i].set_title(f'{title} (цветное)')\n    axes[0, i].axis('off')\n    \n    axes[1, i].imshow(gray, cmap='gray')\n    axes[1, i].set_title(f'{title} (оттенки серого)')\n    axes[1, i].axis('off')\n\nplt.tight_layout()\nplt.show()\n\n# Сохранение для дальнейшего использования\nfor i, (img, gray) in enumerate(zip(images, gray_images)):\n    cv2.imwrite(f'image{i+1}_color.jpg', img)\n    cv2.imwrite(f'image{i+1}_gray.jpg', gray)",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0JCaE37cBW7t",
    "outputId": "7a1a49a0-4e7d-4099-e244-7e6dc78456ab"
   },
   "id": "0JCaE37cBW7t",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "В работе использовались изображения, соответствующие по стилю набору ImageNet:\n",
    "\n",
    "Изображение 1 (Кошка) — демонстрирует животное с четкой текстурой шерсти и выраженными контурами. Наличие глаз, ушей и усов создает области с высоким градиентом, что позволяет оценить способность SIFT выделять характерные точки на биологических объектах.\n",
    "\n",
    "Изображение 2 (Собака) — показывает другое животное в ином ракурсе, с отличиями в текстуре и освещении. Различия в структуре шерсти и форме морды позволяют проверить устойчивость дескрипторов к межклассовым вариациям.\n",
    "\n",
    "Такая пара изображений хорошо подходит для анализа работы SIFT, так как содержит как сходные черты (оба - домашние животные), так и существенные различия, что позволяет оценить качество сопоставления в реалистичных условиях."
   ],
   "metadata": {
    "id": "Q-gVgdXSDhW-"
   },
   "id": "Q-gVgdXSDhW-"
  },
  {
   "cell_type": "code",
   "source": "def create_sift_detector() -> cv2.SIFT:\n    \"\"\"Создаёт SIFT детектор с поддержкой разных версий OpenCV.\"\"\"\n    try:\n        return cv2.SIFT_create()\n    except AttributeError:\n        return cv2.xfeatures2d.SIFT_create()\n\n\ndef visualize_keypoints(\n    img: np.ndarray,\n    keypoints: List,\n    max_points: int = 150,\n    color: Tuple[int, int, int] = (0, 255, 0),\n    title: str = \"Ключевые точки\"\n) -> None:\n    \"\"\"Визуализирует ключевые точки на изображении.\n    \n    Args:\n        img: Исходное изображение\n        keypoints: Список ключевых точек\n        max_points: Максимальное количество точек для отображения\n        color: Цвет точек (BGR)\n        title: Заголовок графика\n    \"\"\"\n    vis_img = cv2.drawKeypoints(\n        img,\n        keypoints[:max_points],\n        None,\n        flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS,\n        color=color\n    )\n    \n    plt.figure(figsize=(10, 8))\n    plt.imshow(cv2.cvtColor(vis_img, cv2.COLOR_BGR2RGB))\n    plt.axis('off')\n    plt.title(title, fontsize=14, pad=20)\n    plt.tight_layout()\n    plt.show()\n\n\n# Создание детектора и извлечение ключевых точек\ndetector = create_sift_detector()\n\nkeypoints_list = []\ndescriptors_list = []\n\nfor i, gray in enumerate(gray_images):\n    kp, desc = detector.detectAndCompute(gray, None)\n    keypoints_list.append(kp)\n    descriptors_list.append(desc)\n    print(f\"Изображение {i+1}: {len(kp)} ключевых точек\")\n\nprint(f\"\\nРазмерность дескриптора: {descriptors_list[0].shape[1]} измерений\")\n\n# Визуализация ключевых точек\nvisualize_keypoints(\n    images[0], keypoints_list[0], \n    color=(0, 255, 0),\n    title=f'Характерные точки изображения 1 (первые 150 из {len(keypoints_list[0])})'\n)\n\nvisualize_keypoints(\n    images[1], keypoints_list[1],\n    color=(255, 0, 0),\n    title=f'Характерные точки изображения 2 (первые 150 из {len(keypoints_list[1])})'\n)",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IJPHQdhoESdF",
    "outputId": "70d640b2-81da-4b95-adc1-ba7e576af883"
   },
   "id": "IJPHQdhoESdF",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Результаты извлечения:\n",
    "\n",
    "На первом изображении обнаружено 2181 ключевых точек\n",
    "На втором изображении обнаружено 403 ключевых точек\n",
    "Каждая точка описывается дескриптором размерностью 128 измерений\n",
    "Дескрипторы представляют собой градиентные гистограммы локальных окрестностей\n",
    "Ключевые точки выделяются в местах с выраженными перепадами яркости (углы, границы, текстуры). Каждая точка характеризуется:\n",
    "\n",
    "Координатами (x, y)\n",
    "Радиусом окрестности (size)\n",
    "Углом ориентации (angle)\n",
    "Качеством отклика (response)"
   ],
   "metadata": {
    "id": "lHEGioNdEwVv"
   },
   "id": "lHEGioNdEwVv"
  },
  {
   "cell_type": "code",
   "source": "def filter_matches_lowe(\n    matches: List,\n    ratio_threshold: float = 0.75\n) -> List:\n    \"\"\"Фильтрует совпадения по критерию Лоу.\n    \n    Args:\n        matches: Список пар совпадений от knnMatch\n        ratio_threshold: Пороговое значение для фильтрации\n        \n    Returns:\n        Отфильтрованный список совпадений\n    \"\"\"\n    filtered = []\n    for primary, secondary in matches:\n        if primary.distance < ratio_threshold * secondary.distance:\n            filtered.append(primary)\n    return sorted(filtered, key=lambda x: x.distance)\n\n\ndef analyze_matches(matches: List) -> dict:\n    \"\"\"Вычисляет статистику по совпадениям.\n    \n    Args:\n        matches: Список совпадений\n        \n    Returns:\n        Словарь со статистикой\n    \"\"\"\n    distances = [m.distance for m in matches]\n    return {\n        'count': len(matches),\n        'mean': np.mean(distances),\n        'min': min(distances),\n        'max': max(distances),\n        'std': np.std(distances)\n    }\n\n\n# Сопоставление дескрипторов\nRATIO_THRESHOLD = 0.75\n\nmatcher = cv2.BFMatcher()\ninitial_matches = matcher.knnMatch(descriptors_list[0], descriptors_list[1], k=2)\n\nfiltered_matches = filter_matches_lowe(initial_matches, RATIO_THRESHOLD)\nstats = analyze_matches(filtered_matches)\n\nprint(\"Анализ совпадений:\")\nprint(f\"  Первоначально найдено пар: {len(initial_matches)}\")\nprint(f\"  После фильтрации: {stats['count']}\")\nprint(f\"  Коэффициент фильтрации: {RATIO_THRESHOLD}\")\nprint(f\"  Процент оставшихся: {stats['count']/len(initial_matches)*100:.1f}%\")\n\n# Визуализация\nfig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n\n# Гистограмма расстояний\ndistances = [m.distance for m in filtered_matches]\nax1.hist(distances, bins=30, color='skyblue', edgecolor='black', alpha=0.7)\nax1.axvline(stats['mean'], color='red', linestyle='--', label=f\"Среднее: {stats['mean']:.2f}\")\nax1.set_xlabel('Расстояние между дескрипторами', fontsize=12)\nax1.set_ylabel('Количество совпадений', fontsize=12)\nax1.set_title('Распределение расстояний совпадений', fontsize=14, pad=15)\nax1.legend()\nax1.grid(True, alpha=0.3)\n\n# Визуализация совпадений\nvis_matches = cv2.drawMatches(\n    images[0], keypoints_list[0],\n    images[1], keypoints_list[1],\n    filtered_matches[:50],\n    None,\n    flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS,\n    matchColor=(0, 255, 0)\n)\n\nax2.imshow(cv2.cvtColor(vis_matches, cv2.COLOR_BGR2RGB))\nax2.axis('off')\nax2.set_title(f'Визуализация совпадений (первые 50, порог={RATIO_THRESHOLD})', fontsize=14, pad=15)\n\nplt.tight_layout()\nplt.show()\n\n# Статистика\nprint(f\"\\nСтатистика по совпадениям:\")\nprint(f\"  Среднее расстояние: {stats['mean']:.3f}\")\nprint(f\"  Минимальное: {stats['min']:.3f}\")\nprint(f\"  Максимальное: {stats['max']:.3f}\")\nprint(f\"  Стандартное отклонение: {stats['std']:.3f}\")",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "u1qe3LNJFM9y",
    "outputId": "bafebae8-5427-4be3-b005-b4dcb081e3ca"
   },
   "id": "u1qe3LNJFM9y",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Интерпретация результатов:\n",
    "\n",
    "Метод сопоставления: Использован алгоритм Brute-Force с поиском k ближайших соседей (k=2)\n",
    "Фильтрация совпадений: Применен критерий Лоу для отсеивания ложных соответствий\n",
    "Визуализация: Линии соединяют соответствующие ключевые точки на двух изображениях\n",
    "Качество совпадений: Оценивается по евклидову расстоянию между дескрипторами\n",
    "Критерий Лоу (Lowe's ratio test) позволяет отфильтровать ненадежные совпадения, сравнивая расстояние до ближайшего соседа с расстоянием до второго ближайшего. Если отношение меньше порога (0.75), совпадение считается надежным."
   ],
   "metadata": {
    "id": "qYiA4cDhFZS_"
   },
   "id": "qYiA4cDhFZS_"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **2. Анализ шагов алгоритма SIFT**\n",
    "\n",
    "### **2.1 Масштабно-пространственная фильтрация (Difference-of-Gaussians)**\n",
    "\n",
    "**Операции над изображением:**\n",
    "1. **Построение гауссовой пирамиды** - последовательное применение свертки с гауссовыми ядрами возрастающего размера:\n",
    "   \n",
    "   $L(x,y,\\sigma) = G(x,y,\\sigma) \\ast I(x,y)$\n",
    "   \n",
    "   где $G(x,y,\\sigma) = \\frac{1}{2\\pi\\sigma^2}e^{-\\frac{x^2+y^2}{2\\sigma^2}}$\n",
    "\n",
    "2. **Вычисление разности гауссианов** - попиксельное вычитание изображений соседних масштабов:\n",
    "   \n",
    "   $D(x,y,\\sigma) = L(x,y,k\\sigma) - L(x,y,\\sigma)$\n",
    "   где $k$ - коэффициент масштабирования\n",
    "\n",
    "**Вычисление производных (backpropagation):**\n",
    "- **Свертка с гауссовым ядром**: линейная операция, градиент вычисляется как свертка с тем же ядром:\n",
    "  \n",
    "  $\\frac{\\partial L}{\\partial I} = G(x,y,\\sigma)$\n",
    "\n",
    "- **Разность гауссианов**: линейное вычитание, производные:\n",
    "  \n",
    "  $\\frac{\\partial D}{\\partial L_1} = 1$, $\\frac{\\partial D}{\\partial L_2} = -1$\n",
    "\n",
    "- **Цепное правило**: градиенты распространяются через последовательность операций\n",
    "\n",
    "### **2.2 Выбор экстремумов (поиск ключевых точек)**\n",
    "\n",
    "**Операции над изображением:**\n",
    "1. **3D-поиск максимумов** - сравнение каждого пикселя с 26 соседями (8 в текущем масштабе + 9 в масштабе выше + 9 в масштабе ниже)\n",
    "2. **Пороговая фильтрация** - удаление точек с низким контрастом: $|D(x,y,\\sigma)| < T_{contrast}$\n",
    "3. **Подавление краевых точек** - анализ отношения главных собственных значений матрицы Гессе\n",
    "\n",
    "**Вычисление производных (backpropagation):**\n",
    "- **Жесткий максимум**: недифференцируемая операция, требует замены на мягкую версию:\n",
    "  \n",
    "  Используем soft-argmax: $p_i = \\frac{e^{\\beta D_i}}{\\sum_j e^{\\beta D_j}}$\n",
    "  \n",
    "  где $\\beta$ - параметр температуры\n",
    "\n",
    "- **Пороговая фильтрация**: можно заменить на сигмоидную функцию:\n",
    "  \n",
    "  $f(D) = \\frac{1}{1+e^{-\\alpha(D-T)}}$\n",
    "\n",
    "- **Анализ матрицы Гессе**: дифференцируем через собственные разложения с регуляризацией\n",
    "\n",
    "### **2.3 Назначение ориентаций ключевым точкам**\n",
    "\n",
    "**Операции над изображением:**\n",
    "1. **Вычисление градиентов**:\n",
    "   \n",
    "   $m(x,y) = \\sqrt{(L(x+1,y)-L(x-1,y))^2 + (L(x,y+1)-L(x,y-1))^2}$\n",
    "   \n",
    "   $\\theta(x,y) = \\text{atan2}(L(x,y+1)-L(x,y-1), L(x+1,y)-L(x-1,y))$\n",
    "\n",
    "2. **Построение гистограммы ориентаций** - 36 бинов, трилинейная интерполяция\n",
    "3. **Выбор доминирующих направлений** - пики в гистограмме выше 80% от максимума\n",
    "\n",
    "**Вычисление производных (backpropagation):**\n",
    "- **Вычисление градиентов**: конечные разности, производные:\n",
    "  \n",
    "  $\\frac{\\partial m}{\\partial L} = \\frac{1}{m}\\left[(L(x+1,y)-L(x-1,y))\\frac{\\partial}{\\partial L}(L(x+1,y)-L(x-1,y)) + \\cdots\\right]$\n",
    "\n",
    "- **Функция atan2**: дифференцируема везде кроме начала координат:\n",
    "  \n",
    "  $\\frac{d}{dx}\\text{atan2}(y,x) = \\frac{-y}{x^2+y^2}$\n",
    "\n",
    "- **Трилинейная интерполяция**: линейная операция по весам\n",
    "\n",
    "### **2.4 Построение гистограмм градиентов**\n",
    "\n",
    "**Операции над изображением:**\n",
    "1. **Вращение окрестности** - координатная система выравнивается по ориентации ключевой точки\n",
    "2. **Разбиение на 4×4 субрегиона** - окно 16×16 пикселей\n",
    "3. **Вычисление 8-биновых гистограмм** для каждого субрегиона с трилинейной интерполяцией:\n",
    "   - Интерполяция по пространственным координатам (x, y)\n",
    "   - Интерполяция по ориентации (θ)\n",
    "\n",
    "**Вычисление производных (backpropagation):**\n",
    "- **Вращение координат**: линейное преобразование, якобиан - матрица вращения\n",
    "- **Билинейная интерполяция**: дифференцируема, градиенты по ближайшим пикселям\n",
    "- **Накопление в гистограммах**: суммирование взвешенных вкладов, производные по весам интерполяции\n",
    "\n",
    "### **2.5 Нормализация дескрипторов**\n",
    "\n",
    "**Операции над изображением:**\n",
    "1. **L2-нормализация**:\n",
    "   \n",
    "   $\\mathbf{d}_{\\text{norm}} = \\frac{\\mathbf{d}}{||\\mathbf{d}||_2}$\n",
    "\n",
    "2. **Пороговое отсечение** - ограничение максимального значения компонент (обычно 0.2)\n",
    "3. **Повторная нормализация** для устойчивости к изменениям освещенности\n",
    "\n",
    "**Вычисление производных (backpropagation):**\n",
    "- **L2-нормализация**: дифференцируемая операция:\n",
    "  \n",
    "  $\\frac{\\partial}{\\partial d_i}\\left(\\frac{d_j}{||\\mathbf{d}||}\\right) = \\frac{\\delta_{ij}||\\mathbf{d}|| - d_j\\frac{d_i}{||\\mathbf{d}||}}{||\\mathbf{d}||^2}$\n",
    "\n",
    "- **Пороговое отсечение**: недифференцируемо в точке отсечения, можно заменить на мягкую версию:\n",
    "  \n",
    "  $\\text{soft\\_clip}(x, threshold) = \\frac{threshold \\cdot \\tanh(x/threshold) + threshold}{2}$\n",
    "## **3. Реализация SIFT (псевдокод)**\n",
    "\n",
    "### **3.1 Алгоритм в псевдокоде**\n",
    "\n",
    "**Вход:** изображение $I(x,y)$  \n",
    "**Выход:** ключевые точки $K$ с дескрипторами $D$\n",
    "\n",
    "---\n",
    "\n",
    "**Шаг 1: Построение гауссовой пирамиды**\n",
    "\n",
    "Для октав $o = 0,1,\\dots,O-1$ и уровней $s = 0,1,\\dots,S+2$:\n",
    "\n",
    "$$\n",
    "L(x,y,\\sigma) = G(x,y,\\sigma) \\ast I(x,y)\n",
    "$$\n",
    "\n",
    "где $G(x,y,\\sigma) = \\frac{1}{2\\pi\\sigma^2}\\exp\\left(-\\frac{x^2+y^2}{2\\sigma^2}\\right)$,  \n",
    "$\\sigma = \\sigma_0 \\cdot 2^{o+s/S}$, $\\sigma_0 = 1.6$.\n",
    "\n",
    "---\n",
    "\n",
    "**Шаг 2: Вычисление разности гауссианов (DoG)**\n",
    "\n",
    "Для каждой октавы:\n",
    "\n",
    "$$\n",
    "D(x,y,\\sigma) = L(x,y,k\\sigma) - L(x,y,\\sigma)\n",
    "$$\n",
    "\n",
    "где $k = 2^{1/S}$.\n",
    "\n",
    "---\n",
    "\n",
    "**Шаг 3: Поиск локальных экстремумов**\n",
    "\n",
    "Для каждого пикселя $(x,y,\\sigma)$ в $D$:\n",
    "\n",
    "Проверить, является ли $D(x,y,\\sigma)$ локальным экстремумом в $3\\times3\\times3$ окне (8 соседей в том же масштабе + 9 в масштабе выше + 9 в масштабе ниже).\n",
    "\n",
    "Если да → кандидат в ключевые точки.\n",
    "\n",
    "---\n",
    "\n",
    "**Шаг 4: Уточнение координат ключевой точки**\n",
    "\n",
    "Квадратичная аппроксимация:\n",
    "\n",
    "$$\n",
    "\\Delta\\mathbf{x} = -\\mathbf{H}^{-1} \\nabla D\n",
    "$$\n",
    "\n",
    "где $\\mathbf{x} = (x,y,\\sigma)^T$, $\\nabla D$ — градиент $D$,  \n",
    "$\\mathbf{H}$ — матрица Гессе (гессиан) размерности $3\\times3$:\n",
    "\n",
    "$$\n",
    "\\mathbf{H} = \\begin{bmatrix}\n",
    "\\frac{\\partial^2 D}{\\partial x^2} & \\frac{\\partial^2 D}{\\partial x \\partial y} & \\frac{\\partial^2 D}{\\partial x \\partial \\sigma} \\\\\n",
    "\\frac{\\partial^2 D}{\\partial y \\partial x} & \\frac{\\partial^2 D}{\\partial y^2} & \\frac{\\partial^2 D}{\\partial y \\partial \\sigma} \\\\\n",
    "\\frac{\\partial^2 D}{\\partial \\sigma \\partial x} & \\frac{\\partial^2 D}{\\partial \\sigma \\partial y} & \\frac{\\partial^2 D}{\\partial \\sigma^2}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Если $|\\Delta\\mathbf{x}| > 0.5$ в любом измерении → сдвинуть точку и повторить.\n",
    "\n",
    "---\n",
    "\n",
    "**Шаг 5: Фильтрация слабых точек**\n",
    "\n",
    "1. **По контрасту:** если $|D(\\mathbf{x})| < T_{\\text{contrast}}$ → отбросить.\n",
    "   Обычно $T_{\\text{contrast}} = 0.03$.\n",
    "\n",
    "2. **По краям:** используя матрицу Гессе $H_{2\\times2}$ для пространственных координат:\n",
    "\n",
    "   $$\n",
    "   \\text{Tr}(\\mathbf{H})^2 / \\text{Det}(\\mathbf{H}) < \\frac{(r+1)^2}{r}\n",
    "   $$\n",
    "   \n",
    "   где $r = 10$ (пороговое отношение собственных значений).\n",
    "   Если условие не выполняется → точка на краю, отбросить.\n",
    "\n",
    "---\n",
    "\n",
    "**Шаг 6: Назначение ориентации**\n",
    "\n",
    "Для каждой ключевой точки в масштабе $\\sigma$:\n",
    "\n",
    "1. Вычислить градиенты в окрестности радиуса $3\\sigma$:\n",
    "\n",
    "   $$\n",
    "   m(x,y) = \\sqrt{(L(x+1,y)-L(x-1,y))^2 + (L(x,y+1)-L(x,y-1))^2}\n",
    "   $$\n",
    "   \n",
    "   $$\n",
    "   \\theta(x,y) = \\arctan_2(L(x,y+1)-L(x,y-1),\\ L(x+1,y)-L(x-1,y))\n",
    "   $$\n",
    "\n",
    "2. Построить гистограмму из 36 бинов (по 10°):\n",
    "\n",
    "   $$\n",
    "   h(\\theta_k) = \\sum_{x,y} w(x,y) \\cdot m(x,y) \\cdot \\delta(\\theta(x,y) \\in \\text{бин}_k)\n",
    "   $$\n",
    "   \n",
    "   где $w(x,y) = \\exp\\left(-\\frac{(x-x_0)^2+(y-y_0)^2}{2(1.5\\sigma)^2}\\right)$ — гауссов вес.\n",
    "\n",
    "3. Найти пики гистограммы: ориентации с $h > 0.8 \\cdot h_{\\max}$.\n",
    "\n",
    "---\n",
    "\n",
    "**Шаг 7: Построение дескрипторов**\n",
    "\n",
    "Для каждой ориентированной ключевой точки:\n",
    "\n",
    "1. Взять окно $16\\times16$ пикселей (в масштабе ключевой точки).\n",
    "2. Разделить на $4\\times4$ клетки (по $4\\times4$ пикселя каждая).\n",
    "3. Для каждой клетки вычислить 8-бинную гистограмму ориентаций (трилинейная интерполяция):\n",
    "\n",
    "   - Интерполяция по пространству ($x$, $y$)\n",
    "   - Интерполяция по ориентации ($\\theta$)\n",
    "   \n",
    "   Вклад каждого градиента распределяется между соседними бинами и клетками.\n",
    "\n",
    "4. Получить вектор из $4\\times4\\times8 = 128$ элементов.\n",
    "\n",
    "---\n",
    "\n",
    "**Шаг 8: Нормализация дескрипторов**\n",
    "\n",
    "1. **L2-нормализация:**\n",
    "   \n",
    "   $$\n",
    "   \\mathbf{v} = \\frac{\\mathbf{d}}{\\|\\mathbf{d}\\|_2}\n",
    "   $$\n",
    "\n",
    "2. **Пороговое отсечение (clipping):**\n",
    "   \n",
    "   $$\n",
    "   v_i' = \\min(v_i, 0.2)\n",
    "   $$\n",
    "\n",
    "3. **Повторная нормализация:**\n",
    "   \n",
    "   $$\n",
    "   \\mathbf{d}_{\\text{final}} = \\frac{\\mathbf{v}'}{\\|\\mathbf{v}'\\|_2}\n",
    "   $$\n",
    "\n"
   ],
   "metadata": {
    "id": "VreWv9pFFpDt"
   },
   "id": "VreWv9pFFpDt"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**4. Сверточная нейронная сеть: ResNet и затухающие градиенты**"
   ],
   "metadata": {
    "id": "4SgJiPCQI_hD"
   },
   "id": "4SgJiPCQI_hD"
  },
  {
   "cell_type": "code",
   "source": "from torch.utils.data import Dataset, DataLoader, random_split\n\n\nclass SyntheticImageDataset(Dataset):\n    \"\"\"Синтетический датасет с изображениями разных паттернов.\n    \n    Создаёт изображения 5 классов с характерными паттернами:\n    - Класс 0: Вертикальные красные полосы\n    - Класс 1: Горизонтальные зелёные полосы\n    - Класс 2: Синие круги\n    - Класс 3: Жёлтые квадраты\n    - Класс 4: Диагональные фиолетовые полосы\n    \n    Args:\n        num_samples: Количество изображений\n        num_classes: Количество классов\n        image_size: Размер изображения (квадратное)\n    \"\"\"\n    \n    def __init__(self, num_samples: int = 1000, num_classes: int = 5, image_size: int = 64):\n        self.num_samples = num_samples\n        self.num_classes = num_classes\n        self.image_size = image_size\n        self.data = []\n        self.labels = []\n        \n        self._generate_data()\n    \n    def _generate_data(self) -> None:\n        \"\"\"Генерирует синтетические изображения.\"\"\"\n        for i in range(self.num_samples):\n            img = torch.rand(3, self.image_size, self.image_size)\n            label = i % self.num_classes\n            \n            if label == 0:  # Вертикальные красные полосы\n                for x in range(self.image_size):\n                    if x % 10 < 5:\n                        img[0, :, x] = 0.8\n                        img[1, :, x] = 0.2\n                        img[2, :, x] = 0.2\n                        \n            elif label == 1:  # Горизонтальные зелёные полосы\n                for y in range(self.image_size):\n                    if y % 10 < 5:\n                        img[0, y, :] = 0.2\n                        img[1, y, :] = 0.8\n                        img[2, y, :] = 0.2\n                        \n            elif label == 2:  # Синие круги\n                cx = np.random.randint(20, self.image_size - 20)\n                cy = np.random.randint(20, self.image_size - 20)\n                r = np.random.randint(10, 20)\n                for x in range(self.image_size):\n                    for y in range(self.image_size):\n                        if (x - cx)**2 + (y - cy)**2 <= r**2:\n                            img[0, x, y] = 0.2\n                            img[1, x, y] = 0.2\n                            img[2, x, y] = 0.8\n                            \n            elif label == 3:  # Жёлтые квадраты\n                x0 = np.random.randint(10, self.image_size - 30)\n                y0 = np.random.randint(10, self.image_size - 30)\n                size = np.random.randint(15, 25)\n                img[0, x0:x0+size, y0:y0+size] = 0.8\n                img[1, x0:x0+size, y0:y0+size] = 0.8\n                img[2, x0:x0+size, y0:y0+size] = 0.2\n                \n            elif label == 4:  # Диагональные фиолетовые полосы\n                for x in range(self.image_size):\n                    for y in range(self.image_size):\n                        if (x + y) % 20 < 10:\n                            img[0, x, y] = 0.8\n                            img[1, x, y] = 0.2\n                            img[2, x, y] = 0.8\n\n            self.data.append(img)\n            self.labels.append(label)\n\n    def __len__(self) -> int:\n        return self.num_samples\n\n    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n        return self.data[idx], self.labels[idx]\n\n\n# Создание датасета\nNUM_SAMPLES = 500\nNUM_CLASSES = 5\nIMAGE_SIZE = 64\nBATCH_SIZE = 32\nTRAIN_RATIO = 0.8\n\ndataset = SyntheticImageDataset(\n    num_samples=NUM_SAMPLES,\n    num_classes=NUM_CLASSES,\n    image_size=IMAGE_SIZE\n)\n\ntrain_size = int(TRAIN_RATIO * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n\nprint(f\"Размер обучающей выборки: {len(train_dataset)}\")\nprint(f\"Размер валидационной выборки: {len(val_dataset)}\")",
   "metadata": {
    "id": "xBHztxZrKxEU",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "30a7bccd-0318-4d93-dd79-2c861b068ace"
   },
   "id": "xBHztxZrKxEU",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "class SimpleCNN(nn.Module):\n    \"\"\"Простая CNN для классификации изображений.\n    \n    Архитектура: Conv -> Pool -> Conv -> Pool -> FC\n    \n    Args:\n        num_classes: Количество классов для классификации\n    \"\"\"\n    \n    def __init__(self, num_classes: int = 5):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.fc = nn.Linear(32 * 16 * 16, num_classes)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.pool(F.relu(self.conv1(x)))  # 64x64 -> 32x32\n        x = self.pool(F.relu(self.conv2(x)))  # 32x32 -> 16x16\n        x = x.view(x.size(0), -1)\n        return self.fc(x)\n\n\n# Инициализация моделей\ncnn_model = SimpleCNN(num_classes=NUM_CLASSES)\n\nresnet_model = resnet18(weights=None)\nresnet_model.fc = nn.Linear(resnet_model.fc.in_features, NUM_CLASSES)\n\nprint(\"Модели инициализированы:\")\nprint(f\"  SimpleCNN: {sum(p.numel() for p in cnn_model.parameters())} параметров\")\nprint(f\"  ResNet18: {sum(p.numel() for p in resnet_model.parameters())} параметров\")",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T0wSSzDQLmFU",
    "outputId": "1c4ef2b7-0067-44da-d463-f8927be37e2a"
   },
   "id": "T0wSSzDQLmFU",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def compute_gradient_norms(model: nn.Module) -> List[float]:\n    \"\"\"Вычисляет нормы градиентов для всех параметров модели.\n    \n    Args:\n        model: PyTorch модель\n        \n    Returns:\n        Список норм градиентов\n    \"\"\"\n    norms = []\n    for param in model.parameters():\n        if param.grad is not None:\n            norms.append(param.grad.norm().item())\n    return norms\n\n\ndef train_epoch(\n    model: nn.Module,\n    loader: DataLoader,\n    criterion: nn.Module,\n    optimizer: torch.optim.Optimizer\n) -> Tuple[float, float, float]:\n    \"\"\"Обучает модель одну эпоху.\n    \n    Args:\n        model: Модель для обучения\n        loader: DataLoader с данными\n        criterion: Функция потерь\n        optimizer: Оптимизатор\n        \n    Returns:\n        Кортеж (средний loss, accuracy, средняя норма градиентов)\n    \"\"\"\n    model.train()\n    total_loss = 0\n    correct = 0\n    epoch_gradients = []\n\n    for x, y in loader:\n        optimizer.zero_grad()\n        out = model(x)\n        loss = criterion(out, y)\n        loss.backward()\n\n        gradients = compute_gradient_norms(model)\n        if gradients:\n            epoch_gradients.append(np.mean(gradients))\n\n        optimizer.step()\n\n        total_loss += loss.item()\n        correct += (out.argmax(1) == y).sum().item()\n\n    avg_loss = total_loss / len(loader)\n    accuracy = correct / len(loader.dataset)\n    avg_gradient = np.mean(epoch_gradients) if epoch_gradients else 0\n\n    return avg_loss, accuracy, avg_gradient\n\n\ndef train_model(\n    model: nn.Module,\n    train_loader: DataLoader,\n    criterion: nn.Module,\n    optimizer: torch.optim.Optimizer,\n    epochs: int = 5\n) -> Tuple[List[float], List[float], List[float]]:\n    \"\"\"Обучает модель заданное количество эпох.\n    \n    Args:\n        model: Модель для обучения\n        train_loader: DataLoader с обучающими данными\n        criterion: Функция потерь\n        optimizer: Оптимизатор\n        epochs: Количество эпох\n        \n    Returns:\n        Кортеж списков (losses, accuracies, gradients)\n    \"\"\"\n    losses, accuracies, gradients = [], [], []\n\n    for epoch in range(epochs):\n        loss, acc, grad = train_epoch(model, train_loader, criterion, optimizer)\n        losses.append(loss)\n        accuracies.append(acc)\n        gradients.append(grad)\n        print(f\"Эпоха {epoch+1}: loss={loss:.4f}, accuracy={acc:.4f}\")\n\n    return losses, accuracies, gradients",
   "metadata": {
    "id": "kQrO9zphLrFu"
   },
   "id": "kQrO9zphLrFu",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Обучение моделей\nLEARNING_RATE = 0.001\nNUM_EPOCHS = 5\n\ncriterion = nn.CrossEntropyLoss()\n\n# Обучение CNN\nprint(\"Обучение SimpleCNN:\")\nprint(\"-\" * 40)\ncnn_optimizer = optim.Adam(cnn_model.parameters(), lr=LEARNING_RATE)\ncnn_losses, cnn_accuracies, cnn_gradients = train_model(\n    cnn_model, train_loader, criterion, cnn_optimizer, epochs=NUM_EPOCHS\n)\n\n# Обучение ResNet\nprint(\"\\nОбучение ResNet18:\")\nprint(\"-\" * 40)\nresnet_optimizer = optim.Adam(resnet_model.parameters(), lr=LEARNING_RATE)\nresnet_losses, resnet_accuracies, resnet_gradients = train_model(\n    resnet_model, train_loader, criterion, resnet_optimizer, epochs=NUM_EPOCHS\n)",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51pYwvefLvHR",
    "outputId": "76ad8e01-1987-4626-f7e3-450349bf2c58"
   },
   "id": "51pYwvefLvHR",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "def get_layer_gradients(model: nn.Module, layer_names: List[str]) -> dict:\n    \"\"\"Извлекает градиенты по указанным слоям.\n    \n    Args:\n        model: Модель\n        layer_names: Список имён слоёв для извлечения\n        \n    Returns:\n        Словарь {имя_слоя: норма_градиента}\n    \"\"\"\n    gradients = {}\n    for name, param in model.named_parameters():\n        if 'weight' in name and param.grad is not None:\n            for layer_name in layer_names:\n                if layer_name in name:\n                    gradients[layer_name] = param.grad.norm().item()\n                    break\n    return gradients\n\n\n# Визуализация результатов\nfig = plt.figure(figsize=(15, 10))\n\n# 1. График потерь\nax1 = fig.add_subplot(2, 3, 1)\nax1.plot(cnn_losses, 'b-o', label='SimpleCNN')\nax1.plot(resnet_losses, 'r-s', label='ResNet18')\nax1.set_xlabel('Эпоха')\nax1.set_ylabel('Loss')\nax1.set_title('Функция потерь')\nax1.legend()\nax1.grid(True, alpha=0.3)\n\n# 2. График точности\nax2 = fig.add_subplot(2, 3, 2)\nax2.plot(cnn_accuracies, 'b-o', label='SimpleCNN')\nax2.plot(resnet_accuracies, 'r-s', label='ResNet18')\nax2.set_xlabel('Эпоха')\nax2.set_ylabel('Accuracy')\nax2.set_title('Точность на обучении')\nax2.legend()\nax2.grid(True, alpha=0.3)\n\n# 3. График градиентов\nax3 = fig.add_subplot(2, 3, 3)\nax3.plot(cnn_gradients, 'b-o', label='SimpleCNN')\nax3.plot(resnet_gradients, 'r-s', label='ResNet18')\nax3.set_xlabel('Эпоха')\nax3.set_ylabel('Норма градиентов')\nax3.set_title('Средняя норма градиентов')\nax3.legend()\nax3.grid(True, alpha=0.3)\n\n# 4. Градиенты по слоям CNN\nax4 = fig.add_subplot(2, 3, 4)\ncnn_layer_grads = get_layer_gradients(cnn_model, ['conv1', 'conv2', 'fc'])\nif cnn_layer_grads:\n    layers = list(cnn_layer_grads.keys())\n    grads = list(cnn_layer_grads.values())\n    ax4.bar(range(len(layers)), grads, color='steelblue')\n    ax4.set_xticks(range(len(layers)))\n    ax4.set_xticklabels(layers, rotation=45)\nax4.set_ylabel('Норма градиентов')\nax4.set_title('Градиенты по слоям SimpleCNN')\n\n# 5. Градиенты по слоям ResNet\nax5 = fig.add_subplot(2, 3, 5)\nresnet_layers = ['conv1', 'layer1', 'layer2', 'layer3', 'layer4', 'fc']\nresnet_layer_grads = get_layer_gradients(resnet_model, resnet_layers)\nif resnet_layer_grads:\n    grads = [resnet_layer_grads.get(layer, 0) for layer in resnet_layers]\n    ax5.bar(range(len(resnet_layers)), grads, color='indianred')\n    ax5.set_xticks(range(len(resnet_layers)))\n    ax5.set_xticklabels(resnet_layers, rotation=45)\nax5.set_ylabel('Норма градиентов')\nax5.set_title('Градиенты по слоям ResNet18')\n\n# 6. Сравнение финальных градиентов\nax6 = fig.add_subplot(2, 3, 6)\ncomparison = [cnn_gradients[-1], resnet_gradients[-1]]\nax6.bar(['SimpleCNN', 'ResNet18'], comparison, color=['steelblue', 'indianred'])\nax6.set_ylabel('Норма градиентов (эпоха 5)')\nax6.set_title('Сравнение градиентов')\n\nplt.tight_layout()\nplt.show()",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 864
    },
    "id": "2Nfx16GVMC5Y",
    "outputId": "f3b9b769-1096-4480-e8d2-875f0dd3cdb6"
   },
   "id": "2Nfx16GVMC5Y",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Анализ результатов\nprint(\"=\" * 60)\nprint(\"АНАЛИЗ РЕЗУЛЬТАТОВ\")\nprint(\"=\" * 60)\n\nprint(f\"\\n1. Финальные показатели:\")\nprint(f\"   SimpleCNN: Loss={cnn_losses[-1]:.4f}, Accuracy={cnn_accuracies[-1]:.4f}\")\nprint(f\"   ResNet18:  Loss={resnet_losses[-1]:.4f}, Accuracy={resnet_accuracies[-1]:.4f}\")\n\nprint(f\"\\n2. Изменение градиентов за обучение:\")\ncnn_grad_change = (cnn_gradients[-1] - cnn_gradients[0]) / cnn_gradients[0] * 100\nresnet_grad_change = (resnet_gradients[-1] - resnet_gradients[0]) / resnet_gradients[0] * 100\nprint(f\"   SimpleCNN: {cnn_grad_change:+.1f}%\")\nprint(f\"   ResNet18:  {resnet_grad_change:+.1f}%\")\n\nprint(f\"\\n3. Отношение градиентов между слоями:\")\ncnn_layer_grads = get_layer_gradients(cnn_model, ['conv1', 'conv2', 'fc'])\nresnet_layer_grads = get_layer_gradients(resnet_model, ['conv1', 'layer1', 'layer2', 'layer3', 'layer4', 'fc'])\n\nif 'conv1' in cnn_layer_grads and 'conv2' in cnn_layer_grads:\n    ratio = cnn_layer_grads['conv2'] / cnn_layer_grads['conv1']\n    print(f\"   SimpleCNN (conv2/conv1): {ratio:.3f}\")\n\nif 'layer1' in resnet_layer_grads and 'layer4' in resnet_layer_grads:\n    ratio = resnet_layer_grads['layer4'] / resnet_layer_grads['layer1']\n    print(f\"   ResNet18 (layer4/layer1): {ratio:.3f}\")\n\nprint(f\"\\n4. Выводы:\")\nprint(\"   - ResNet показывает более стабильные градиенты благодаря skip-connections\")\nprint(\"   - В SimpleCNN градиенты затухают сильнее в ранних слоях\")\nprint(\"   - Skip-connections в ResNet предотвращают проблему затухающих градиентов\")",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DxL5GrwRMRer",
    "outputId": "f4b4f155-e300-4a6b-a542-9e49a31ee7ee"
   },
   "id": "DxL5GrwRMRer",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}